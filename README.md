# ğŸ“Š Stock Data Intelligence Dashboard

ğŸ”— **Live Demo:** https://sahiltripathy005.github.io/Stock_Dashboard/

ğŸ”— **API Docs:** https://stock-dashboard-kkpr.onrender.com/docs

A mini financial data intelligence platform built using **Python, FastAPI, Pandas, and SQLite**, designed to demonstrate real-world stock data handling, analytical feature engineering, REST API development, and visualization.

This project goes beyond basic dashboards by focusing on **data correctness, analytical integrity, and deployment-aware engineering**, which are critical in fintech and data-driven systems.

## ğŸ¯ Objective

The objective of this project is to build a practical stock data platform that demonstrates the ability to:

- Collect and clean real historical stock market data  
- Perform meaningful financial transformations using Pandas  
- Design and expose REST APIs using FastAPI  
- Visualize stock trends and risk metrics  
- Handle real-world deployment challenges  

Special emphasis is placed on **data preparation and feature engineering**, aligning with the evaluation criteria where data handling carries the highest weight.

## ğŸ” Project Focus & Differentiation

Most stock dashboards simply display prices.  
This project focuses on how financial data is **prepared, validated, stored, and served**, which is where real-world complexity exists.

### Key Differentiators

- Rolling analytics computed with correct time-series ordering  
- Explicit handling of missing values from rolling windows  
- Consistent data semantics across **CSV â†’ Database â†’ API â†’ Frontend**  
- Deployment-safe database bootstrapping  
- Backend-first analytical design  

## ğŸ› ï¸ Tech Stack

### Backend
- Python  
- FastAPI  
- SQLAlchemy  
- SQLite  

### Data Processing
- Pandas  
- NumPy  

### Frontend
- HTML  
- CSS  
- JavaScript  
- Chart.js  

### Deployment
- **Backend:** Render  
- **Frontend:** GitHub Pages  

## ğŸ“¥ Data Collection

Historical stock market data was sourced from a public dataset containing daily **OHLCV** values for multiple companies across several years.

Each record includes:
- Date  
- Open price  
- High price  
- Low price  
- Close price  
- Trading volume  
- Stock symbol  

A **CSV-based dataset** was intentionally used to ensure reproducibility and avoid API rate limits during deployment.

## ğŸ§¹ Data Cleaning & Preparation (Primary Focus Area)

Data preparation was treated as a **first-class concern**, reflecting its importance in real financial analytics.

### Key Steps
- Converting date columns to proper datetime formats  
- Ensuring numeric consistency across OHLCV values  
- Sorting data chronologically per stock symbol  
- Handling missing values generated by rolling windows  
- Maintaining consistent column naming across the entire pipeline  

This ensured **analytical correctness** and prevented subtle time-series errors.

## ğŸ“ Feature Engineering & Metrics

The following financial metrics were derived using **Pandas**:

- **Daily Return**  
  `(Close âˆ’ Open) / Open`

- **7-Day Moving Average**  
  Rolling mean of closing prices per stock symbol

- **52-Week High / Low**  
  Maximum and minimum prices computed across historical data

- **Volatility**  
  7-day rolling standard deviation of daily returns  

All rolling metrics were computed **per symbol** and in **correct chronological order** to maintain analytical validity.

## ğŸ—„ï¸ Database Design

A relational schema was designed to store both **raw prices** and **derived analytics**.

Each record contains:
- Stock symbol  
- Trading date  
- Open, High, Low, Close, Volume  
- Daily return  
- 7-day moving average  
- 52-week high  
- 52-week low  
- Volatility  

This design supports **efficient querying** for both raw data and analytical summaries.

## ğŸ”Œ Backend API Design

The backend exposes **RESTful endpoints** using **FastAPI**.

### Available Endpoints

- **GET `/companies`**  
  Returns the list of available stock symbols.

- **GET `/data/{symbol}`**  
  Returns the most recent 30 days of stock data, including derived metrics.

- **GET `/summary/{symbol}`**  
  Returns the 52-week high, low, and average closing price.

- **GET `/compare?symbol1=AAPL&symbol2=MSFT`**  
  Compares recent performance of two stocks.

Special care was taken to preserve **chronological ordering** so that rolling metrics remain valid in API responses.

## â˜ï¸ Deployment-Aware Data Handling

A key challenge addressed in this project was ensuring that **derived metrics remain available in deployed environments**.

Since deployment platforms do not automatically execute local preprocessing scripts, the backend includes a **startup bootstrap mechanism** that populates the database from a preprocessed dataset when required.

This ensures:
- Consistent results locally and in production  
- Reproducible analytics  
- No reliance on manual data loading  

This approach reflects **real-world data engineering practices**.

## ğŸ“ˆ Visualization Dashboard

The frontend dashboard allows users to:
- Select a company  
- View closing price trends  
- Overlay the 7-day moving average  
- Inspect recent volatility values  

**Chart.js** is used for rendering interactive charts with explicit handling of **rolling-window gaps** to ensure clean visualization.

## ğŸ” Key Engineering Insights

Some important engineering considerations addressed in this project:

- Rolling indicators require strict time-series ordering  
- Deployment environments expose hidden data assumptions  
- Analytical correctness matters more than cosmetic visuals  
- Backend and frontend must agree on data semantics  

These considerations were intentionally handled to demonstrate **production readiness**.

## â–¶ï¸ Running the Project Locally

- Clone the repository  
- Install dependencies from `requirements.txt`  
- Run data preprocessing scripts  
- Start the FastAPI server  
- Open the frontend in a browser  

The backend automatically **initializes the database** when required.

## ğŸš€ Future Enhancements

Potential extensions include:
- Advanced risk metrics such as beta or Sharpe ratio  
- Caching for frequently accessed symbols  
- Machine learningâ€“based price trend estimation  
- Enhanced UI with advanced filtering and comparison  

## ğŸ Conclusion

This project prioritizes **data quality**, **analytical integrity**, and **backend robustness** over superficial complexity.

It demonstrates the ability to work with real financial datasets, build reliable APIs, and manage deployment-time data challenges â€” skills that are essential in **fintech and data-driven engineering roles**.
